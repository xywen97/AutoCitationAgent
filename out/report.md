# Citation Report

## Existing citations found

- Count: 0
- Seed expansion used: no

## BibTeX update summary

- bib_path: cases\references.bib
- existing_entries_count: 0
- new_entries_added_count: 6
- new_bibkeys_added: UnknownIntents, UnknownThe, UnknownAgent, UnknownVerification, UnknownFormal, UnknownAgenta

## Claims

### S0

- sentence: The Symbolic Governor acts as the "System 2" component of the agent.
- claim_type: definition
- rationale: The sentence defines the role of the Symbolic Governor as the 'System 2' component, which is a specific conceptual claim requiring citation to prior work or authoritative source.
- status: NEED_MANUAL
- notes: No reliable BibTeX (missing DOI).
- queries: Symbolic Governor as System 2 cognition in AI agent architectures, Formal verification of Symbolic Governor in agent orchestration, Role of Symbolic Governor in runtime policy enforcement for AI agents, Agent Constitution and Scheduler Interception with Symbolic Governor, Policy Engine and Reference Monitor integration with Symbolic Governor, Formal methods for System 2 components in hybrid AI systems
- selected papers:

### S1

- sentence: It is the root of trust.
- claim_type: definition
- rationale: The phrase 'root of trust' is a technical term that typically requires citation to clarify its specific meaning and context.
- status: NEED_MANUAL
- notes: No reliable BibTeX (missing DOI).
- queries: Symbolic Governor as root of trust in AI agent orchestration, Formal verification of Policy Engine and Reference Monitor in AI systems, Scheduler Interception and access control lists for secure AI agent architectures, Runtime policy enforcement with Symbolic Governor and System 2 cognition, Formal methods for ensuring root of trust in AI agent control mechanisms, Resource Limits and Taint Checks in formally verified AI agent orchestration
- selected papers:

### S2

- sentence: Unlike the LLM, the Governor is implemented in deterministic code (e.
- claim_type: method_description
- rationale: The claim about the Governor being implemented in deterministic code is a specific technical detail that requires verification.
- status: NEED_MANUAL
- notes: No reliable BibTeX (missing DOI).
- queries: Symbolic Governor deterministic code formal verification, Formal verification of AI agent orchestration with Symbolic Governor, Deterministic code in AI agent control mechanisms, Policy Engine and Reference Monitor in AI agent orchestration, Scheduler Interception and runtime policy enforcement in AI systems, Formal methods for resource limits and access control in AI agents
- selected papers:

### S3

- sentence: g., Python, Rust) and is formally verifiable.
- claim_type: prior_work
- rationale: The claim that the language (Python, Rust) is formally verifiable is a factual claim that requires citation to support formal verification status.
- status: NEED_MANUAL
- notes: No reliable BibTeX (missing DOI).
- queries: Formal verification of AI agent orchestration in Python and Rust, Symbolic Governor and formal methods for AI agent control, Runtime policy enforcement and Scheduler Interception in AI systems, Formal verification of Policy Engine and Reference Monitor in AI agents, Access Control Lists and Taint Checks for secure AI agent orchestration, Deterministic code and System 2 cognition in formally verifiable AI architectures
- selected papers:

### S4

- sentence: It is responsible for the high-level orchestration of the agent's workflow and the strict enforcement of the Agent Constitution.
- claim_type: method_description
- rationale: The sentence describes a specific responsibility and enforcement mechanism of the Agent Constitution, which is a technical claim requiring citation to prior work or formal specification.
- status: NEED_MANUAL
- notes: No reliable BibTeX (missing DOI).
- queries: Agent Constitution enforcement in AI agent orchestration, Formal verification of high-level AI agent workflow control, Symbolic Governor for strict policy enforcement in AI agents, Scheduler Interception and Policy Engine in agent orchestration, Reference Monitor role in AI agent workflow management, Formal methods for runtime policy enforcement in multiagent systems
- selected papers:

### S5

- sentence: The Governor implements a Scheduler Interception mechanism.
- claim_type: method_description
- rationale: The sentence describes a specific mechanism implemented by the Governor, which is a technical claim requiring citation to support the method's existence or details.
- status: NEED_MANUAL
- notes: No reliable BibTeX (missing DOI).
- queries: Governor Scheduler Interception formal verification AI agent orchestration, Symbolic Governor Scheduler Interception policy enforcement AI systems, Formal methods Scheduler Interception in AI agent architectures, Runtime policy enforcement Scheduler Interception Governor AI, Scheduler Interception and Reference Monitor in AI agent control, Formal verification of Scheduler Interception mechanisms in AI agents
- selected papers:

### S7

- sentence: In ArbiterOS, the LLM emits an intent to call a tool.
- claim_type: method_description
- rationale: The sentence describes a specific mechanism in ArbiterOS involving LLM intent emission, which is a technical detail requiring citation to support the claim.
- status: NEED_MANUAL
- notes: No candidates met thresholds. Provide manual review.
- queries: ArbiterOS LLM intent tool call formal verification, Symbolic Governor tool invocation in AI agent orchestration, Formal methods for intent emission in AI agent systems, Policy Engine and Scheduler Interception for tool calls in ArbiterOS, Runtime policy enforcement for LLM tool invocation, Reference Monitor and access control in AI agent tool calls
- selected papers:
  - Intents (None) DOI=10.1007/978-1-4842-6914-5_4 score=0.315
  - The Reasons that Agents Act: Intention and Instrumental Goals (None) DOI=10.65109/vzce5163 score=0.315
  - Agent-Based Explanations in AI: Towards an Abstract Framework (None) DOI=10.1007/978-3-030-51924-7_1 score=0.315

### S8

- sentence: The Governor intercepts this intent, suspends the Probabilistic CPU, and evaluates the intent against the active Policy Engine.
- claim_type: method_description
- rationale: Describes a specific mechanism involving the Governor, Probabilistic CPU, and Policy Engine which likely requires citation to prior work or formal definition.
- status: NEED_MANUAL
- notes: No candidates met thresholds. Provide manual review.
- queries: Symbolic Governor intercepting intent in AI agent orchestration, Probabilistic CPU suspension and Policy Engine evaluation in AI systems, Formal verification of Policy Engine and Scheduler Interception mechanisms, Runtime policy enforcement using Reference Monitor and Symbolic Governor, Agent Constitution and System 2 cognition in formal AI control architectures, Access Control Lists and Taint Checks for secure AI agent orchestration
- selected papers:
  - Verification and Enforcement of Access Control Policies (None) DOI=10.1007/s10703-013-0187-3 score=0.45

### S10

- sentence: g., Resource Limits, Taint Checks, ACLs) does the Governor execute the tool.
- claim_type: method_description
- rationale: The sentence describes a specific method or mechanism involving Resource Limits, Taint Checks, and ACLs in the Governor's execution, which requires citation to support the technical claim.
- status: NEED_MANUAL
- notes: No candidates met thresholds. Provide manual review.
- queries: Formal verification of Symbolic Governor in AI agent orchestration, Runtime policy enforcement using Resource Limits and Taint Checks in AI systems, Access Control Lists and Reference Monitor for secure AI agent architectures, Scheduler Interception and Policy Engine for deterministic code execution in AI agents, Formal methods for hybrid AI systems with human-in-the-loop control, Security and access control mechanisms in multiagent systems with formal guarantees
- selected papers:
  - Formal Verification of Open Multi-Agent Systems (None) DOI=10.65109/shtg3566 score=0.5349999999999999

### S11

- sentence: This "Reference Monitor" pattern  ensures that the agent's cognitive instability cannot propagate to the external world.
- claim_type: prior_work
- rationale: The statement attributes a specific security property to the 'Reference Monitor' pattern, which is a technical claim requiring support from prior work or formal verification literature.
- status: NEED_MANUAL
- notes: No candidates met thresholds. Provide manual review.
- queries: Reference Monitor pattern formal verification AI agent cognitive stability, Symbolic Governor and Reference Monitor in AI agent orchestration, Formal methods for preventing cognitive instability propagation in AI agents, Policy Engine and Reference Monitor for runtime enforcement in AI systems, Agent Constitution and Scheduler Interception for secure AI agent control, Access Control Lists and Taint Checks in AI agent formal verification
- selected papers:
  - Agent-Based Explanations in AI: Towards an Abstract Framework (None) DOI=10.1007/978-3-030-51924-7_1 score=0.5499999999999999

