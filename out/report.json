{
  "anchor_summary": {
    "topic": "Symbolic Governor in AI Systems",
    "subareas": [
      "Formal Verification",
      "Deterministic Programming",
      "Agent-Based Systems"
    ],
    "key_terms": [
      "Symbolic Governor",
      "System 2",
      "Root of Trust",
      "LLM",
      "Deterministic Code",
      "Formal Verification"
    ],
    "likely_venues": [
      "Artificial Intelligence Journal",
      "Journal of Automated Reasoning",
      "ACM Transactions on Intelligent Systems and Technology"
    ],
    "exclusions": [
      "Non-deterministic systems",
      "Unverified AI models",
      "General Machine Learning without formal methods"
    ]
  },
  "existing_citations_count": 0,
  "seed_expansion_used": false,
  "bib_path": "cases\\references.bib",
  "existing_entries_count": 12,
  "new_entries_added_count": 19,
  "new_bibkeys_added": [
    "Jain_1996",
    "UnknownTesting",
    "UnknownFormal",
    "UnknownCS",
    "UnknownPDF",
    "UnknownAnchoring",
    "UnknownSolving",
    "UnknownC",
    "UnknownSymbolic",
    "UnknownSymbolica",
    "UnknownDefeating",
    "UnknownSymbolicb",
    "Unknowntowards",
    "UnknownCombining",
    "UnknownSymbolicc",
    "UnknownPDFa",
    "Granatyr_2015",
    "UnknownAi",
    "UnknownEnsuring"
  ],
  "warnings": [],
  "claims": [
    {
      "sid": "S0",
      "sentence": "The Symbolic Governor acts as the \"System 2\" component of the agent.",
      "rationale": "The term 'Symbolic Governor' and its role as 'System 2' requires citation to support the claim.",
      "claim_type": "definition",
      "queries": [
        "Symbolic Governor in AI systems",
        "System 2 component in agent-based systems",
        "Formal verification of deterministic programming with Symbolic Governor",
        "Root of Trust in AI systems with Symbolic Governor",
        "Deterministic code and its relation to Symbolic Governor"
      ],
      "selected": [
        {
          "paper_id": null,
          "title": "[PDF] Verifying Nondeterministic Implementations of Deterministic Systems",
          "authors": [
            "Jain, Alok",
            "Nelson, Kyle",
            "Bryant, Randal E."
          ],
          "year": 1996,
          "venue": null,
          "abstract": "high-level behavior as a set of operations. A mapping relates the sequential semantics of these\noperations to the underlying nondeterminism in the implementation. Symbolic Trajectory Evalu-\nation, a modified form of symbolic simulation, is used to perform the actual verification. The\nmethodology is currently being used to verify portions of a superscalar processor which imple-... bridge the wide gap between the abstract specification and the implementation\u2019s often\nradical deviation from the sequential execution model.\nA methodology for formal verification must ensure that such a system functions cor-\nrectly under all possible execution sequences. Since there is an infinite number of exe-\ncution sequences, we verify each operation individually and then reason about\nstitching arbitrary operations together to form execution sequences.\nThe goal is to develop a methodology with which a designer can show that an imple-\n1. This work partially funded by Semiconductor Research Corporation # 95-DC-068.... ulation called Symbolic Trajectory Evaluation[1] is used to perform the verification\ntask. We use the term trajectory specification and trajectory assertions partly for histor-\nical reasons. Our trajectory assertions are a generalization of the trajectory assertions\nintroduced by Seger[4]. The justification is that the assertions define a set of trajecto-... ries in the simulator.\nThe formal verification methodology presented in this paper is currently being used to\nverify a superscalar processor which implements the PowerPC architecture[12]. The\nprocessor has several complex features such as pipeline interlocks, multiple instruction\nissue, and branch prediction to advance the state of the art in verification.... divergent behavior.\nSymbolic Trajectory Evaluation (STE) has been used earlier to verify trajectory asser-\ntions. Beatty[3] mapped each abstract assertion into a set of symbolic patterns. STE\nwas used to verify the set of symbolic patterns on the circuit. The set of symbolic pat-\nterns corresponded to a single sequence of states in a state diagram. Seger[4] extended... STE to perform fixed point computations to verify a single sequence of states aug-\nmented with a limited set of loops. In our work, trajectory assertions are general state\ndiagrams. We have extended STE to deal with generalized trajectory assertions.\nOur work has some resemblance to the capabilities provided by the Symbolic Model\nVerifier (SMV)[5][6]. SMV requires a closed system. The environment is modeled as a",
          "doi": "10.1007/bfb0031803",
          "url": "https://www.cs.cmu.edu/~bryant/pubdir/fmcad96.pdf",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.5,
          "authority": 0.2,
          "final": 0.45499999999999996,
          "evidence_snippet": "Symbolic execution is one technique used for formal verification.",
          "why": "This paper emphasizes symbolic execution, which is relevant to the decision-making aspect of the Symbolic Governor."
        },
        {
          "paper_id": null,
          "title": "Testing, Debugging, Program Verification - Formal Verification, Part I",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "P is correct with respect to S\nThe Main Steps towards Formal Verification\n1. Write a specification of a given program that can be proven\n2. Devic a correctness proof method without exhaustive case analysis\n3. Design mathematically rigorous proof rules: \u201ccalculus\u201d\nTDV: Verification I\n/GU\n2012-11-27\n3 / 37... What is Symbolic Execution?\nConcrete Execution\n\u25b6State: a concrete valuation of all variables (stack) and fields (heap)\n\u25b6(Execution) Path: finite OR infinite sequence of states that a\nprogram passes as it executes\n\u25b6Program Counter: States along the path are annotated with next\n(sub-)statement to be executed.\n\u25b6Initial state given explicitly\nTDV: Verification I\n/GU\n2012-11-27\n6 / 37... What is Symbolic Execution?\nSymbolic Execution\n\u25b6State: a \u201csymbolic\u201d valuation of all variables and fields.\n\u25b6New symbols to denote initial value of variables etc.\n\u25b6Each term represents a set of possible concrete values\n\u25b6Execution Tree: finite OR infinite tree of states\n\u25b6Program Counter: States in the tree are annotated with next... (sub-)statement to be executed\n\u25b6Path Condition: Annotations on branching state transitions.\n\u25b6Each concrete execution path is an instance of some symbolic path\nthrough the tree\n\u25b6Initial state given explicitly or by a symbolic precondition\nTDV: Verification I\n/GU\n2012-11-27\n7 / 37... Symbolic Execution by Example\n{target := t0}\nSymbolic Program State\nint [] array = a0;\nFirst Active Statement (Program Counter)\nint\nlow = 0;\nint\nhigh = array.length -1;\nwhile ( low\n<= high ) {\nint\nmid = (low + high) / 2 ;... Symbolic Execution by Example\na0!=null && a0.length > 0 && t0==a0[ (a0.length-1)/2 ]\n{target := t0 | array := a0 | low := 0 | high := a0.length-1 |\nmid := (a0.length-1)/2}\nreturn (a0.length-1)/2;\nTDV: Verification I\n/GU\n2012-11-27\n10 / 37",
          "doi": null,
          "url": "https://www.cse.chalmers.se/edu/year/2012/course/TDA566_Testing_debugging_and_verification/FormalVerification1-handout.pdf",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.5,
          "authority": 0.2,
          "final": 0.45499999999999996,
          "evidence_snippet": "Symbolic execution is one technique used for formal verification.",
          "why": "This paper emphasizes symbolic execution, which is relevant to the decision-making aspect of the Symbolic Governor."
        },
        {
          "paper_id": null,
          "title": "Formal Verification & Symbolic Execution | W/ Trail Of Bits",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "{ts:227} formal  verification  is  going  to  be  the \n act  of  proving  of  disproving  a  given\n{ts:233} \n property  of  the  system  this  is  usually \n\n{ts:235} done  through  a  mathematical  model  of  the \n system  and  the  property  there's  that\n{ts:239} \n word  again  property  you're  seeing  that... {ts:252} Properties  by  throwing  random  data  at \n your  system  whereas  formal  verification\n{ts:256} \n tries  to  break  properties  using \n\n{ts:257} mathematical  proofs  and  there  are  many \n different  ways  to  do  formal  verification\n{ts:261} \n such  as  symbolic  execution  and  Abstract... {ts:342} from  our  code  we're  going  to  convert \n this  function  to  a  mathematical  logical\n{ts:347} \n representation  of  every  execution  path \n\n{ts:350} from  our  code  once  we  have  a  set  of  math \n functions  we  can  push  those  into  a\n{ts:354} \n solver  which  will  tell  us  if  a  property... {ts:509} representation  said  hey  I've \n mathematically  proven  that  there  is  a\n{ts:513} \n scenario  where  path2  is  executed  and \n\n{ts:516} your  function  reverts  so  sat  here  means \n we  mathematically  proved  that  this\n{ts:521} \n invariant  breaks  now  I  manually  created... {ts:603} it's  inputting  into  its  Z3  solver  so  a \n lot  of  stuff  just  happened  here  let's\n{ts:607} \n recap  we  built  some  solidity  we \n\n{ts:610} understood  our  invariant  and  the  next \n two  steps  happened  at  the  same  time  with\n{ts:614} \n sulk  or  Manticore  we  used  a  symbolic",
          "doi": null,
          "url": "https://www.youtube.com/watch?v=izpoxfTSaFs",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.5,
          "authority": 0.2,
          "final": 0.45499999999999996,
          "evidence_snippet": "Symbolic execution is one technique used for formal verification.",
          "why": "This paper emphasizes symbolic execution, which is relevant to the decision-making aspect of the Symbolic Governor."
        },
        {
          "paper_id": null,
          "title": "CS-550 Formal Verification",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "- is the set of states\n- is the set of starting states\n- is the transition relation\n- is the alphabet\nFor and , means that ther is a transition from to on input .\nA few special cases of this general form exist:\n- If is finite, we have a finite state machine\n- If and , then the system is deterministic.... to check if, starting from the invariant and take a step, we can end up outside of the invariant.\nTo understand this condition, it\u2019s useful to think of as determining the assignment of . Then, seeing that contains variables and , it will fix the assignment for the next states . We can then see if the invariant is still true at the next state.... This formula starts at the initial state, then computes all states , and plugs in the final state in the error formula to see if it can be satisfied.\nIf the SAT solver returns\nUNSAT, the error state is not reachable. If it returns\nSAT, the\nSatisfiability checking\nSAT problem\nThe SAT problem is to determine whether a given formula is satisfiable. The problem is NP-complete, but useful heuristics exist.... The transformation works by introducing a fresh variable for each operation (we can think of it as being for each AST node):\nNote that these formulas refer to subterms by their newly introduced equivalent variable. This prevents us from having an explosion of terms in this transformation.\nEach of these equivalences can be converted to CNF by using De Morgan\u2019s law, and switching between and . The resulting conversions are:... |Operation\n|CNF\nNote that the Tseytin transformations can be read as implications. For instance, the transformation can be read as:\n- If and are true, then is true... 1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\ndef DPLL(S: Set[Clause]): Bool = {\nval S' = subsumption(UnitProp(S))\nif (\u2205 \u2208 S') false // an empty clause means the whole thing is unsat... - Merging equivalent leaf nodes (which is what we did above)\n- Merging isomorphic nodes (same variables and same children)\n- Eliminating redundant tests (where both outgoing edges go to the same child)\nDoing this brings us to the following property:\nWith a fixed variable order, the RO-BDD for a Boolean function is unique",
          "doi": null,
          "url": "https://kjaer.io/formal-verification/",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.5,
          "authority": 0.2,
          "final": 0.45499999999999996,
          "evidence_snippet": "Symbolic execution is one technique used for formal verification.",
          "why": "This paper emphasizes symbolic execution, which is relevant to the decision-making aspect of the Symbolic Governor."
        },
        {
          "paper_id": null,
          "title": "[PDF] Symbolic methods for formal verification of industrial control software",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "formal specifications. Although many such procedures can simplistically be thought of\nas an automatic exploration of a system\u2019s state space, the explicit enumeration of each\nreachable state can ofen be avoided. To this end, symbolic methods reason about many\nstates at a time, by representing sets of states and transition relations as logical formulas.... specification is satisfied by the system.\nFigure 1.1 illustrates the general approach to model checking [BK08; Cla+18b].\nTe process begins with formal modelling of the system and formalisation of\nrequirements in terms of the formalisms that are supported by the utilised model\nchecking procedure. Since the results of the model checker only hold w.r.t. the... the application domain, such as information on structure, common patterns,\nand special cases, to overcome what may be a pitfall to a less specialised\nmodel checking procedure.\nSymbolic methods approach the algorithmic challenge by characterising sets of\nstates, and the relations between them, in terms of expressions in a symbolic logic,... e. g. constraints in first-order logic (FOL) or binary decision diagrams (BDDs). In\ncontrast to the explicit enumeration and construction of single states, symbolic\nencodings can be significantly more memory-efficient, when using efficient data\nstructures to represent state sets. If the operations performed on these sets can... is actually empty for x, y \u2208Z, as the constraint is unsatisfiable. To compute\nthe states represented by such expressions, or check the characterised set for\nemptiness, techniques like satisfiability (SAT) and satisfiability modulo theories\n(SMT) checking are needed. In contrast to BDD-based representations, many... operations on such FOL formulas are purely syntactic, so the lazy construction of a\nstate only occurs during the actual SAT check. As a result, SAT-based verification\nprocedures are a common choice for models with many variables, such as those\narising from formalisation of sofware semantics.\nWhile formal methods for general-purpose programming languages have come... [ZRK03], DES will typically feature only Boolean or finite-domain variables and\nspecifications will be given in temporal logics. For such verification tasks, \u2018clas-\nsical\u2019 symbolic model checkers like ITS-tools [Ti15], LTSmin [Kan+15] and\nTINA [BRV04] are particularly well suited and are indeed used in verification of",
          "doi": null,
          "url": "http://publications.rwth-aachen.de/record/835546/files/835546.pdf",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.5,
          "authority": 0.2,
          "final": 0.45499999999999996,
          "evidence_snippet": "Symbolic execution is one technique used for formal verification.",
          "why": "This paper emphasizes symbolic execution, which is relevant to the decision-making aspect of the Symbolic Governor."
        }
      ],
      "status": "NEED_MANUAL",
      "notes": "No candidates met thresholds. Provide manual review."
    },
    {
      "sid": "S1",
      "sentence": "It is the root of trust.",
      "rationale": "The phrase 'root of trust' is a specific term that requires citation to clarify its meaning and context in AI systems.",
      "claim_type": "definition",
      "queries": [
        "Symbolic Governor in AI Systems",
        "Formal Verification of Symbolic Governor",
        "Deterministic Programming with Symbolic Governor",
        "Root of Trust in Agent-Based Systems",
        "LLM and Deterministic Code in AI"
      ],
      "selected": [
        {
          "paper_id": null,
          "title": "Anchoring Agentic AI Governance to a Hardware Root of Trust",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "If we're going to let these agents act on our behalf, we must move from a weak \"trust me\" model (relying on software logs) to a powerful \"prove it to me\" model. That proof can't come from software. It must be forged in silicon.\n\nThis report is your guide to the foundational hardware-level controls\u2014\n\n**Confidential Computing** and **Remote Attestation**\u2014that are not optional add-ons, but the *non-negotiable bedrock* for any sane Agentic AI governance strategy. I will analyze how IBM's current offerings and announced strategy map to this silicon-first imperative.... **Agent Spoofing/Kidnapping:**An attacker steals the agent's model weights from memory\u2014the IP equivalent of stealing the \"brain\" of a $500M R&D investment. **In-Memory Poisoning:**A privileged attacker tampers with the agent's model *in-memory*during its decision loop, subtly \"nudging\" its behavior\u2014for example, convincing a trading agent to consistently round 0.001 cents in its favor.... **Decision-Log Tampering:**An agent makes a catastrophic, non-compliant decision. A bad actor (or the agent itself) alters the software-based audit log to hide the action, breaking all accountability.\n\nThese threats lead to four non-negotiable requirements for agentic AI governance.\n\n**The 4 Pillars of Hardware-Based Governance:** **\ud83d\udee1\ufe0f Isolation:**The agent's \"mind\" (model, data, inference) must be completely isolated *while in use*(in memory), even from the host OS and cloud provider admins. 2... **Attestation:**The agent must be able to *cryptographically prove* *what*code it's running and *that*its environment is a genuine, secure hardware enclave.\n\n\n\n**Immutability:**The agent's core model weights and, most critically, its decision logs must be protected from tampering or deletion.\n\n\n\n**Verifiability:**Governance policies must be demonstrably *enforced*by the infrastructure, not just *monitored*by a dashboard, producing a non-repudiable audit trail.... **Immutability & Verifiability (The \"Anchor\"):**\n\nAt the heart of the Z's security is the Crypto Express module, a FIPS 140-2 Level 4 hardware security module (HSM). This is the physical anchor for the platform's Root of Trust. Its game-changing value for agentic governance is the creation of non-repudiable audit trails.",
          "doi": null,
          "url": "https://www.webmethodman.com/p/anchoring-agentic-ai-governance-to-a-hardware-root-of-trust",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.8,
          "support": 0.7,
          "authority": 0.6,
          "final": 0.7199999999999999,
          "evidence_snippet": "the physical anchor for the platform's Root of Trust",
          "why": "The paper discusses the importance of a hardware root of trust in agentic AI governance, emphasizing its foundational role in ensuring security and accountability."
        },
        {
          "paper_id": null,
          "title": "Solving Deterministic Models",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "Even for a given set of exogenous and parameter values, some\n(nonlinear) models have several steady states\nThe steady state is computed by Dynare with the steady command\nThat command internally uses a nonlinear solver\nS\u00b4ebastien Villemot (CEPREMAP)\nSolving Deterministic Models\nOctober 27, 2013\n7 / 42... A Newton approach\nStart from an initial guess Y (0)\nIterate. Updated solutions Y (k+1) are obtained by solving:\nF(Y (k)) +\n\ufffd\u2202F\n\u2202Y\n\ufffd\ufffd\nY (k+1) \u2212Y (k)\ufffd\n= 0\nTerminal condition:\n||Y (k+1) \u2212Y (k)|| < \u03b5Y and/or ||F(Y (k))|| < \u03b5F\nS\u00b4ebastien Villemot (CEPREMAP)\nSolving Deterministic Models\nOctober 27, 2013\n13 / 42... Block decomposition (1/3)\nIdea: apply a divide-and-conquer technique to model simulation\nPrinciple: identify recursive and simultaneous blocks in the model\nstructure\nFirst block (prologue): equations that only involve variables\ndetermined by previous equations; example: AR(1) processes\nLast block (epilogue): pure output/reporting equations... Block decomposition (2/3)\nForm of the reordered Jacobian\nS\u00b4ebastien Villemot (CEPREMAP)\nSolving Deterministic Models\nOctober 27, 2013\n23 / 42\n\nBlock decomposition (3/3)\nCan provide a significant speed-up on large models\nImplemented in Dynare by Ferhat Mihoubi\nAvailable as option block to the model command\nBigger gains when used in conjunction with bytecode options\nS\u00b4ebastien Villemot (CEPREMAP)\nSolving Deterministic Models\nOctober 27, 2013\n24 / 42... Advantages:\n\u25b6shocks are unexpected at every period\n\u25b6nonlinearities fully taken into account\nInconvenient: solution under certainty equivalence (Jensen inequality\nis violated)\nMethod introduced by Fair and Taylor (1983)\nImplemented in Dynare 4.3 by St\u00b4ephane Adjemian under the\ncommand extended path\nS\u00b4ebastien Villemot (CEPREMAP)\nSolving Deterministic Models\nOctober 27, 2013\n41 / 42",
          "doi": null,
          "url": "https://archives.dynare.org/DynareShanghai2013/deterministic.pdf",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.3,
          "support": 0.4,
          "authority": 0.2,
          "final": 0.33499999999999996,
          "evidence_snippet": "",
          "why": "The paper presents a deterministic technique but does not relate to the concept of trust."
        },
        {
          "paper_id": null,
          "title": "C:/Users/guilherme/Desktop/LNLM_2012_a_2014/Volumes_Publicados/Volume_12_2014/Vol12_Num_2/vol12-no2-art3/Template_L&NLM/symbolicreg - corrigido.dvi",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "execution of b in s1 (or s2) leads to a state s2 and; the execution of c in s0 (or s1) leads to a state s1. Deterministic assumptions\ncan indeed be inappropriate in various practical situations. Figure 1(b) shows a non-deterministic action a2 that when executed... search starts from the initial state and generates successor states, until it reaches a goal state. In a reverse way, the regressive\nsearch starts from the set of states that satisfy a goal formula \u03d5 and generates the predecessor states, until it reaches the initial\nstate s0. A solution for a deterministic planning problem is a plan, i.e., a path in the domain graph, starting from s0 and finishing... in a final state satisfying \u03d5. A solution for a non-deterministic planning problem is a policy, i.e., a mapping from states to actions,\n98... Intuitively, in a weak solution the agent can achieve a goal state; but due to the non-determinism, it does not guarantee to do so;\nin a strong solution the agent always achieves a goal state, in spite of non-determinism; and in a strong-cyclic solution the agent\nalways achieves the goal, under the fairness assumption that execution will eventually exit from all existing cycles [4].... solve planning problems with large state space due to the enumerative representation of the state transitions, i.e., based on set\ntheory. To overcome this limitation planning as symbolic model checking represents the set of states and the transition relations\nof the explicit domain graph as propositional logic formulas and verify the satisfaction of the goal formula \u03d5 by manipulating... Thus, given the symbolic representation of a set of states X, this paper focus on how to compute the predecessor states of X\nusing a symbolic representation of actions (i.e., an implicit and symbolic representation of non-deterministic planning domains),\ninstead of the transition relation (the explicit representation). For this, we define two new operations for non-deterministic... A representing the agent abilities to change the world state. The states are subsets of P (assuming the closed world assumption).\nThe initial state s0 of a planning problem is given by a complete set of properties that defines a unique possible state in the world.\nThe planning goal is given by an incomplete set of properties (i.e., a subset of P) that defines a set of states that satisfies them.",
          "doi": null,
          "url": "https://sbic.org.br/lnlm/wp-content/uploads/sites/4/2016/07/vol12-no2-art3.pdf",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.3,
          "support": 0.4,
          "authority": 0.2,
          "final": 0.33499999999999996,
          "evidence_snippet": "",
          "why": "The paper presents a deterministic technique but does not relate to the concept of trust."
        },
        {
          "paper_id": null,
          "title": "Symbolic Control for Deterministic Hybrid Systems",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "|\n## Symbolic Control for Deterministic Hybrid Systems Symbolic models (a.k.a. finite abstractions) play an important role in the control of hybrid systems. They provide abstract descriptions of the continuous-space systems in which each discrete state and input corresponds to an aggregate of continuous states and inputs of the original system, respectively.... Since symbolic models are finite, they allow us to use automata-theoretic methods to design controllers for hybrid systems with respect to logic specifications such as those expressed as linear temporal logic (LTL) formulae. In general, there exist two types of symbolic models: sound ones whose behaviors (approximately) contain those of the concrete systems and complete ones whose behaviors are (approximately) equivalent to those of the concrete systems.... Remark that existence of complete symbolic models results in a sufficient and necessary guarantee in the sense that there exists a controller enforcing the desired specifications on the symbolic model if and only if there exists a controller enforcing the same specifications on the original system. On the other hand, a sound symbolic model provides only a sufficient guarantee in the sense that failing to find a controller for the desired specifications on the symbolic model does not prevent the existence of a controller for the original system.... Our methodology is based on a divide-and-conquer scheme. In particular, we first (1) partition the overall concrete system into a number of concrete subsystems and construct symbolic models of them individually; (2) then establish a compositional scheme that allows us to construct a symbolic model of the overall network using those of individual ones.... One can leverage the overall constructed symbolic models to synthesize controllers monolithically or also compositionally to achieve some high-level properties. In particular, once symbolic models are constructed for given concrete subsystems, one can design local controllers also compositionally for those symbolic models, and then refine them to the concrete subsystems provided that the given global specification for the overall network is decomposable.... Particularly, based on the assume-guarantee reasoning approach, the local controllers are synthesized by assuming that the other subsystems meet their local specifications. ## Active group members The following group members are actively working on this topic: ## Related publications The following publications are related to this active topic: ## Related software The following software tools are related to this topic:|\n|--|",
          "doi": null,
          "url": "https://www.hyconsys.com/research/symbolic-control-dhs/",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.3,
          "support": 0.4,
          "authority": 0.2,
          "final": 0.33499999999999996,
          "evidence_snippet": "",
          "why": "The paper presents a deterministic technique but does not relate to the concept of trust."
        },
        {
          "paper_id": null,
          "title": "Symbolic Dynamic Programming for Continuous State ...",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI-21)\n4083... the state transitions depend on the arg max of the LP, we\nhave to symbolically obtain closed-form optimal solutions of\nthe LP to provide an exact closed-form solution to the over-\nall MDP. Hence, as our primary technical contribution in this\nwork, we develop a multivariate symbolic arg max operator\nby breaking it into respective arg and max operations and... 2\nDiscrete and Continuous State MDPs\nIn a DC-MDP, vectors of variables (\u20d7b, \u20d7x) = (b1, . . . , bn,\nx1, . . . , xm) represent a state. Each state variable bi (1 \u2264\ni \u2264n) is boolean s.t. bi \u2208{0, 1} and each xj (1 \u2264j \u2264m) is... next state (\u20d7b\u2032, \u20d7x\u2032) conditioned on the current state and action\na; (2) a reward function R(\u20d7b, \u20d7x, a) which specifies the imme-\ndiate reward obtained by taking action a in state (\u20d7b, \u20d7x); and... and R(\u20d7b, \u20d7x, a, \u20d7y\u2217); whereas the transition over binary state\nvariables remains as in Eq.2. Here, \u20d7y\u2217is determined by the\nfollowing LP given a fixed state and action\u20d7b, \u20d7x, a:... bolic substitution [Sanner et al., 2011], SDP simply executes\nvalue iteration in Eqs. 3 and 4 using the DC-MDP definition\ndefined previously and the case operators defined above to\nyield a closed-form, exact symbolic derivation of the value\nfunction [Sanner et al., 2011].... true branch of the parent node, while a dotted line shows the\nfalse branch. Each decision node corresponds to a constraint\nof the LP, and false branches lead to the \u2212\u221enode. This is\nan intuitive way to specify LP infeasibility as we are solving\na maximization problem. We denote the LP as f(\u20d7x,\u20d7b, \u20d7y).... (q2 \u2212\u2206q3 \u2265100) \u2227(q1 + q2 \u2212\u2206q3 < 120) : q1 \u2212\u2206q3",
          "doi": null,
          "url": "https://www.ijcai.org/proceedings/2021/0562.pdf",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.3,
          "support": 0.4,
          "authority": 0.2,
          "final": 0.33499999999999996,
          "evidence_snippet": "",
          "why": "The paper presents a deterministic technique but does not relate to the concept of trust."
        }
      ],
      "status": "NEED_MANUAL",
      "notes": "No candidates met thresholds. Provide manual review."
    },
    {
      "sid": "S2",
      "sentence": "Unlike the LLM, the Governor is implemented in deterministic code (e.",
      "rationale": "The sentence makes a factual comparison between the LLM and the Governor regarding their implementation, which requires citation.",
      "claim_type": "comparison",
      "queries": [
        "Symbolic Governor in AI Systems",
        "Formal Verification of Deterministic Code in AI",
        "Agent-Based Systems with Symbolic Governor",
        "Root of Trust in LLM and Deterministic Programming",
        "Comparative Analysis of Symbolic Governor and LLM"
      ],
      "selected": [
        {
          "paper_id": null,
          "title": "Defeating Non-Determinism in LLMs: Solving AI's ...",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "From a user trust perspective, reproducibility is equally important. Users want to know that when they ask an AI system a question, they\u2019ll get a consistent, reliable answer. If the same question produces wildly different responses, users lose confidence in the system. This is particularly true for applications where users rely on the AI for decision support or information retrieval. Furthermore, reproducibility enables better prompt engineering and optimization. If you can\u2019t reproduce results, you can\u2019t systematically improve your prompts or understand which variations actually work better.... The achievement of deterministic LLM outputs has far-reaching implications for how we build, deploy, and trust AI systems. First and foremost, determinism enables reliable debugging. When a model produces an incorrect or unexpected output, engineers can now reproduce the issue consistently. This transforms debugging from a frustrating game of chance into a systematic process. Engineers can trace the exact computation path that led to the problematic output, identify where the error occurred, and implement fixes with confidence that they\u2019ve actually solved the problem.... Second, determinism dramatically improves auditability. Regulatory bodies, compliance officers, and security teams can now audit AI systems with much greater confidence. When you can reproduce outputs consistently, you can trace the exact factors that influenced a decision. This is particularly important in regulated industries like healthcare, finance, and law, where explainability is a legal requirement. Auditors can verify that the model is behaving as expected and that it\u2019s not producing biased or harmful outputs due to non-deterministic randomness.... Third, benchmarking becomes far more reliable. When comparing two models or two versions of the same model, researchers can now be confident that performance differences are real and not artifacts of randomness. This enables more rigorous scientific evaluation of AI systems and more informed decisions about which models to deploy. Additionally, determinism enables better prompt engineering and optimization. Researchers can systematically test different prompts and measure their effects with confidence that the results are reproducible.... Their experimental validation using Qwen 2.5B showed that perfect determinism is possible\u2014all 1,000 test completions were identical after implementing their solution. This breakthrough has profound implications for AI trust, debugging, auditing, and the deployment of AI systems in regulated industries. As organizations increasingly rely on LLMs for critical applications, the ability to produce reproducible, deterministic outputs will become a fundamental requirement for production-grade AI systems.... Discover how a tiny 7M parameter model outperforms Gemini, DeepSeek, and Claude using recursive reasoning and deep supervision. Learn the revolutionary approach...22 min readAI Machine Learning +3",
          "doi": null,
          "url": "https://www.flowhunt.io/blog/defeating-non-determinism-in-llms/",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.8,
          "support": 0.7,
          "authority": 0.6,
          "final": 0.7199999999999999,
          "evidence_snippet": "the achievement of deterministic LLM outputs has far-reaching implications for how we build, deploy, and trust AI systems.",
          "why": "The paper discusses the importance of determinism in LLMs, aligning with the claim that the Governor is implemented in deterministic code. It provides strong support for the claim by emphasizing the implications of deterministic outputs."
        },
        {
          "paper_id": null,
          "title": "Symbolic AI Systems",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "# Symbolic AI Systems\n\n**- Overview**\n\nSymbolic AI, also known as \"classical AI\" or \"Good Old-Fashioned AI (GOFAI)\", is a subfield of artificial intelligence (AI) that focuses on representing knowledge using human-readable symbols and manipulating those symbols through logical rules to perform reasoning and problem-solving, essentially mimicking how humans think by explicitly encoding knowledge and applying logic to it; making the decision-making process transparent and explainable compared to other AI approaches that rely on pattern recognition from large datasets.... Key characteristics about symbolic AI:\n\n- Representation: Uses symbols to represent real-world concepts, entities, and relationships, allowing for high-level, human-understandable knowledge representation.\n\n- Logic-based reasoning: Leverages formal logic rules to make inferences and draw conclusions based on the encoded knowledge.\n\n- Rule-based systems: Implements knowledge as sets of rules that define how to manipulate symbols and make decisions in specific situations.... Symbolic AI refers to various methods that directly operate on symbolic representations of the world. Symbolic AI has been successful in multiple fields, including planning, scheduling, natural language processing, and gaming.\n\nSymbolic AI methods, such as expert systems, remain the preferred choice in critical real-world applications where human control and transparency are critical and the consequences of errors are severe.... Symbolic AI algorithms can solve problems that are too difficult for traditional AI algorithms. Symbolic AI is good at principled judgments, such as logical reasoning and rule-based diagnoses.\n\nSymbolic reasoning systems are created through human intervention. To build a symbolic reasoning system, humans must first learn the rules by which two phenomena relate, and then hard-code those relationships into a static program.... **- Symbolic Reasoning Systems**\n\nA \"symbolic reasoning system\" in AI refers to a type of AI system that uses symbols to represent knowledge and performs reasoning based on explicit rules and logic, allowing the system to make decisions by manipulating these symbols in a way that mimics human reasoning, often considered more interpretable and transparent compared to purely data-driven approaches like deep learning.... Key characteristics about symbolic reasoning systems:\n- Representation with symbols: Unlike other AI methods that rely on numerical data, symbolic systems use human-readable symbols to represent concepts, entities, and relationships in the real world.\n\n- Rule-based logic: These systems operate based on predefined rules and logical inferences, allowing them to draw conclusions and make decisions by applying these rules to the symbolic representations.",
          "doi": null,
          "url": "http://www.eitc.org/research-opportunities/new-media-and-new-digital-economy/ai-machine-learning-deep-learning-and-neural-networks/ai-research-and-applications/expert-systems-and-applied-ai/symbolic-ai-systems",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.4,
          "support": 0.3,
          "authority": 0.2,
          "final": 0.31999999999999995,
          "evidence_snippet": "",
          "why": "While this paper discusses symbolic AI, it does not provide strong evidence directly supporting the claim about deterministic code."
        },
        {
          "paper_id": null,
          "title": "towards symbolic intelligence with neural networks - PMC",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "Inspired by the strengths of human language, we propose a novel approach that combines deep neural networks with symbolic intelligence to create a new form of representation called \u2018machine language\u2019. We aim to create a language specifically tailored for machines, combining deep neural networks with symbolic reasoning. Through this fusion, we aim to create a representation that inherits the reasoning abilities of discrete symbols and the abstracting capabilities of continuous features, thereby leveraging the advantages of both paradigms.... Rewards are provided for successful performance in the game, while punishments are given for poor performance. This game is referred to as the speak, guess and draw (SGD) game in this paper. The game can be characterized by a tuple *G* = \u2329*D, V, R, A~s~*, *A~l~*, *M*\u232a, *B* = \u2329*T*, \u2026\u232a.... Agent A, denoted as *A~s~*, serves as the speaker who observes the target image and generates a variable-length sequence *M* = (*m*~1~, *m*~2~, \u2026, *m~r~*), representing the machine language. Each *m~i~* represents a discrete symbol. Agent B, referred to as *A~l~*, acts as the listener who receives the machine language *M* and decodes the information to solve two tasks: guessing the target image among distractors and drawing the target based on the provided information.... We employ a neural network model to simulate the SGD game process, depicted in Fig.\u00a01. The model follows an encoder\u2013decoder structure, with the speaker acting as the encoder and the listener as the decoder. For a given random image, the speaker first processes it using a convolutional neural network (CNN) to extract the embedded feature.... Our work takes a different perspective, exploring whether machines can develop their own language, known as machine language, through cooperative visual tasks, without relying on human language. By harnessing the potential of visual big data in shaping machine language, we aim to reconcile symbolic intelligence with neural networks, paving the way for more advanced AI systems. This research direction aligns with the transition towards cognitive intelligence and offers a fresh perspective on language learning in AI, going beyond human language-driven approaches. We firmly believe that emphasizing visual information in language emergence can lead to significant progress in AI capability.... ## Supplementary Material\n\nnwad317_Supplemental_File\n\nClick here for additional data file.^ (2.8MB, pdf) ^",
          "doi": null,
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10862086/",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.4,
          "support": 0.3,
          "authority": 0.2,
          "final": 0.31999999999999995,
          "evidence_snippet": "",
          "why": "While this paper discusses symbolic AI, it does not provide strong evidence directly supporting the claim about deterministic code."
        },
        {
          "paper_id": null,
          "title": "Combining Symbolic and Generative AI |",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "From an expert working on cutting edge neuro symbolic AI solutions, integrating LLM and decision management systems to bring real AI value to the enterprises: \u201c... *Enterprise should not consider Gen AI as the solution to implement their interactive, customer facing, conversation agents. This is too risky business as of today. Rule-based systems have been deployed in the industries for more than 25 years, and are taking millions of decisions per day. Symbolic AI based on deep learning models, such as Generative AI, should be combined with knowledge graph, inference rules and ontologies as they make precise, reasoned, and explainable decisions*.\u201d Link Related articles: \u201cNeuro-Symbolic AI\u201d \u201cHow does neuro-symbolic AI actually work?\u201c... - Follow on WordPress.com\n\n\n\n**Sponsors**\n### Recent Posts\n- Why Ontology driven (LLM-free) AI systems are needed\n\n- LION20: The 20th Learning and Intelligent OptimizatioN Conference\n\n- Decision Agents Today\n\n- Poll Results\n\n- Making Operational Repetitive Decisions Under Uncertainty\n\n- Multiple valid solutions to a business problem\n\n- Decision-Dominant Logic... - The next platform shift is coming\n\n- Monoliths vs Microservices\n\n- \u201cJobs are not disappearing, mediocrity is\u201d\n\n- DecisionCAMP 2025 is now history \u2014 what a journey it\u2019s been!\n\n- DecisionCAMP starts on Sep 22\n\n- Want to build real decision intelligence?\n\n- Can LLMs create something truly new?... - Forecasting\n\n- Fraud Prevention\n\n- Fun\n\n- Games\n\n- Gen AI\n\n- Goal-Oriented\n\n- GPT-4\n\n- HR\n\n- Human Intelligence\n\n- Human-Machine Interaction\n\n- Humor\n\n- Innovation\n\n- Insurance Industry\n\n- Java\n\n- Knowledge Representation\n\n- Languages\n\n- Legal\n\n- LLM... - QA\n\n- Quantum Computing\n\n- Reactive Rules\n\n- Reasoning\n\n- Retail\n\n- RPA\n\n- Rule Engines and BRMS\n\n- Rule Violations\n\n- RuleML\n\n- Scheduling and Resource Allocation\n\n- Science\n\n- Scientists\n\n- Security\n\n- Semantic Web\n\n- Serverless\n\n- SLM\n\n- Software Development\n\n- Sponsors\n\n- Spreadsheets\n\n- Standards\n\n- State Machines\n\n- Supply Chain\n\n- Testing\n\n- Thinking\n\n- Trends\n\n- Uncategorized\n\n- Uncertainty\n\n- Vendors\n\n- Writing",
          "doi": null,
          "url": "https://dmcommunity.org/2024/04/04/combining-symbolic-and-generative-ai/",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.4,
          "support": 0.3,
          "authority": 0.2,
          "final": 0.31999999999999995,
          "evidence_snippet": "",
          "why": "While this paper discusses symbolic AI, it does not provide strong evidence directly supporting the claim about deterministic code."
        },
        {
          "paper_id": null,
          "title": "Symbolic AI: A Complete Guide for Modern AI Applications - Code B",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "Only 15% of AI researchers believe today\u2019s deep learning models can reason in a human-like way without incorporating structured logic (Zhou et al.).\n\nDespite this, nearly all mainstream AI systems rely exclusively on statistical learning trained on massive datasets, with limited transparency.\n\nBut intelligent systems weren\u2019t always built this way.\n\nBefore big data and GPUs reshaped AI, logic-based systems ruled the field. Known as Symbolic AI or Good Old-Fashioned AI (GOFAI), these models didn\u2019t learn; they reasoned.... They used symbolic representations of knowledge (like rules, frames, and ontologies) to perform tasks with precision, traceability, and minimal data.\n\nFast forward to 2025: interest in symbolic methods is resurging\u2014not out of nostalgia, but necessity.\n\nAs AI permeates sensitive fields like healthcare, law, and autonomous systems, the demand for explainable, ethical, and constraint-aware AI is outpacing what opaque models can deliver.... At its core, symbolic AI models intelligence not as a function of patterns, but of logic. Instead of training on data, it starts with explicit knowledge representations, symbols, rules, and ontologies and also uses reasoning engines to manipulate them.\n\nThink of it as AI that can \u201cthink in language and logic,\u201d not just probabilities.... Unlike neural networks, which bury knowledge in millions of weights, symbolic systems operate like a transparent decision tree. Each decision step is traceable, explainable, and governed by formal logic.\n\nFor example, a symbolic system diagnosing a medical condition can show exactly which rules led to a conclusion something neural networks rarely offer.\n\nThe fundamental difference isn't just \u201crules vs. data\u201d; it\u2019s reasoning vs. recognition.... Large language models like GPT-4 and Claude are incredibly fluent, but they\u2019re not naturally logical.\n\nThey often struggle with multi-step reasoning, consistency, and common sense. That\u2019s where symbolic logic comes in.\n\nModern AI systems now use symbolic modules to:\n\nExample: OpenAI\u2019s tool-use research connects LLMs with external symbolic tools to solve tasks more reliably; symbolic engines perform logical tasks the model can\u2019t handle well.... **2. Explainable Diagnosis Systems**\n\nWhile most diagnostic tools now incorporate statistical models, symbolic reasoning is still essential in regulated medical environments.\n\n**3. Legal and Compliance Systems**\n\nLegal domains require more than prediction; they need explainability and traceable logic.\n\nSymbolic AI underpins:\n\n**4. Industrial Systems and Troubleshooting**",
          "doi": null,
          "url": "https://code-b.dev/blog/symbolic-ai",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.4,
          "support": 0.3,
          "authority": 0.2,
          "final": 0.31999999999999995,
          "evidence_snippet": "",
          "why": "While this paper discusses symbolic AI, it does not provide strong evidence directly supporting the claim about deterministic code."
        }
      ],
      "status": "NEED_MANUAL",
      "notes": "No candidates met thresholds. Provide manual review."
    },
    {
      "sid": "S3",
      "sentence": "g., Python, Rust) and is formally verifiable.",
      "rationale": "The statement about formal verifiability implies a factual claim about programming languages that requires citation.",
      "claim_type": "prior_work",
      "queries": [
        "Symbolic Governor in AI Systems formal verification",
        "Deterministic programming with Symbolic Governor",
        "Agent-based systems and Root of Trust in AI",
        "LLM and deterministic code in formal verification",
        "Formal verification of Symbolic Governor in AI"
      ],
      "selected": [
        {
          "paper_id": null,
          "title": "[PDF] Grammars of Formal Uncertainty: When to Trust LLMs in Automated ...",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "Abstract\nLarge language models (LLMs) show remarkable promise for democratizing automated\nreasoning by generating formal specifications. However, a fundamental tension exists:\nLLMs are probabilistic, while formal verification demands deterministic guarantees.\nThis paper addresses this epistemological gap by comprehensively investigating failure\nmodes and uncertainty quantification (UQ) in LLM-generated formal artifacts. Our... reasoning tasks, particularly when generating formal artifacts like SMT-LIB programs, is not a mere\nnuisance but a valuable source of information for guiding verification. Existing methods often ignore\nthis by selecting only the highest-probability output [Chen et al., 2022], a simplification that we argue\nundermines the deterministic correctness guarantees required for formal verification. In contrast, we\ndemonstrate how to systematically capture and analyze this output uncertainty by modeling LLM-generated\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).... review on more ambiguous or structurally complex candidates, and improving error detection strategies.\nThe core contributions of this paper are:\n\u2022 We systematically evaluated frontier LLMs on four formal reasoning datasets, finding SMT-based\nautoformalization significantly boosted accuracy on tasks like ProofWriter (+34.8%) but harmed others\nlike FOLIO (-44.5%), thus quantifying LLM-driven formal verification\u2019s failure modes. We then... metrics, improves calibration, enables selective verification to cut error rates by 14-100% with minimal\nabstention, and suggests modality-aware architectures for enhanced reliability.\n2\nMethodology\nGenerating formal artifacts using ad-hoc Domain-Specific Languages (DSLs) introduces significant\nengineering friction. This friction arises from the need to redesign generators, models, and parsers for... Note: Constrained decoding with deterministic CFGs zeroes out grammar-invalid tokens at inference to\nenforce syntax (e.g., JSON/code). Unlike our PCFG-based UQ, these methods (i) ensure syntax validity\nrather than quantify uncertainty among already well-formed but potentially semantically wrong SMT-LIB\noutputs; and (ii) require white-box token probabilities, or modifications to the LM head, unsuited to... On ProofWriter, a task closely aligned with symbolic logic, SMT-based methods yielded substantial\nimprovements for three models, particularly benefiting those that struggle with direct formal reasoning.\nConversely, on ProntoQA and FOLIO, direct textual reasoning consistently outperformed SMT across\nmost models, suggesting that for these QA tasks, the overhead introduced during autoformalization",
          "doi": null,
          "url": "https://openreview.net/pdf/1bd62aad3dbda001bef71c29125c2be51f974644.pdf",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.7,
          "support": 0.6,
          "authority": 0.3,
          "final": 0.59,
          "evidence_snippet": "LLMs are probabilistic, while formal verification demands deterministic guarantees.",
          "why": "The paper discusses the tension between probabilistic outputs of LLMs and the deterministic nature required for formal verification, which is relevant to the claim. It also explores methods to improve formal reasoning accuracy."
        },
        {
          "paper_id": null,
          "title": "Trust and Reputation Models for Multiagent Systems",
          "authors": [
            "Granatyr, Jones",
            "Botelho, Vanderson",
            "Lessing, Otto Robert",
            "Scalabrin, Edson Em\u00edlio",
            "Barth\u00e8s, Jean-Paul",
            "Enembreck, Fabr\u00edcio"
          ],
          "year": 2015,
          "venue": null,
          "abstract": "## Content\n## Cited ByView all\n\n- Niu LCai QLi KRen FYu X(2025)A reputation-aided negotiation mechanism for multi-agent society based on blockchainEngineering Applications of Artificial Intelligence10.1016/j.engappai.2024.109390\n\n**138**:PBOnline publication date: 20-Feb-2025https://dl.acm.org/doi/10.1016/j.engappai.2024.109390... - Shang RHsieh GShah CDas SGreen BVarshney KGanapini MRenda A(2024)Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI TrustProceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society10.5555/3716662.3716779(1343-1356)Online publication date: 21-Oct-2024https://dl.acm.org/doi/10.5555/3716662.3716779... - [Securing Agent-Oriented Systems: An Argumentation and Reputation-based Approach](https://doi.org/10.1109/itng.2007.175)\n- [Context-Dependent Reputation Management for Soft Security in Multi Agent Systems](https://doi.org/10.1109/wiiat.2008.174)... - [Presumptive selection of trust evidence](https://doi.org/10.1145/1329125.1329327)\n- [A specification of the Agent Reputation and Trust (ART) testbed: experimentation and competition for trust in agent societies](https://doi.org/10.1145/1082473.1082551)... - [TRAVOS: Trust and Reputation in the Context of Inaccurate Information Sources](https://doi.org/10.1007/s10458-006-5952-x)\n- [A Reputation-Based Multi-Agent Model for Network Resource Selection](https://doi.org/10.4236/ijcns.2009.28089)... - [CORE: A Trust Model for Agent Coalition Formation](https://doi.org/10.1109/icnc.2009.612)",
          "doi": "10.1145/2816826",
          "url": "https://dl.acm.org/doi/10.1145/2816826",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.4,
          "authority": 0.3,
          "final": 0.42,
          "evidence_snippet": "we focus on Domain-Specific Languages (DSLs), which LLMs often struggle to generate.",
          "why": "The paper discusses formal verification of code generated by AI, which relates to the claim about formal verifiability."
        },
        {
          "paper_id": null,
          "title": "Ai Window Of Opportunity",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "The AI agent economy could break trust \u2013 or transform it. Image: Getty Images\n\n- The growth of the AI agent economy presents threats to trust levels \u2013 and opportunities to reimagine trust.\n\n- Trust in AI is twofold, resting on perceptions of the technology's competence and intent.\n\n- As autonomous AI proliferates, we must rethink trust across three different levels.... At the heart of trust are two foundational components: competence (the ability to execute) and intent (the purpose behind actions). While few now question the competence of advanced technologies, intent remains a foggy frontier.... ## Ways to earn trust\n\nAs autonomous agents proliferate, we must rethink how trust functions across three key domains:... **Agent-to-agent trust.**Trust between AI agents is formed through the exchange of signals \u2013 performance history, reputational data and predictable behaviour. Agents will evaluate one another based on competence (technical execution, reliability) and intent (alignment of goals, transparency of decision-making). Trust in this space becomes an engineering problem: how to design systems that can assess, verify and adapt trust over time.... **Human-to-agent trust.**For humans to trust AI agents, those agents must display persistent identity and predictable behaviour. People trust consistency. Just as we remember reliable partners, AI agents must remember and adapt to users, offering continuity and coherence in interaction. Trust erodes when AI behaves erratically or pretends to be something it\u2019s not. Authenticity and memory must be built into agent design.... ## The foundations of AI-era trust\n\nOne of the greatest challenges to trust in AI remains a lack of clarity around agent intent. For example, autonomous vehicles may be statistically safer than human drivers, yet they are still distrusted by many due to uncertainty about the values guiding their decisions.\n\nThis points to a broader need for transparent, explainable intent within AI systems \u2013 not just capabilities, but motivations. From a systems perspective, we also face technical challenges: how to ensure seamless and secure data exchange, how to verify agent identity across platforms, and how to create common protocols that allow for the transmission of not just information, but trust itself.... ## AI window of opportunity\n\nThe next five years offer a narrow but critical window to shape how trust functions in a world of autonomous agents. The global AI agents market size is projected to reach $50.31 billion by 2030, according to Grand View Research. As the agent economy evolves, the stakes will be higher than ever. Fraud and security threats could multiply exponentially unless robust trust frameworks are established.",
          "doi": null,
          "url": "https://www.weforum.org/stories/2025/07/ai-agent-economy-trust/",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.4,
          "authority": 0.3,
          "final": 0.42,
          "evidence_snippet": "we focus on Domain-Specific Languages (DSLs), which LLMs often struggle to generate.",
          "why": "The paper discusses formal verification of code generated by AI, which relates to the claim about formal verifiability."
        },
        {
          "paper_id": null,
          "title": "Ensuring Trust and Privacy in AI Agent Systems - Artificial Code",
          "authors": [],
          "year": null,
          "venue": null,
          "abstract": "As I mentioned in my last weekly trend article I\u2019ve recently read a thought-provoking perspective from Stefano Gatti's newsletter: the responsibility question in agent systems. He notes that we're delegating tasks to increasingly unpredictable and non-deterministic systems. His concern about accountability is valid, and here's where I see potential solutions: blockchain and cryptocurrency could provide the transparency and accountability framework needed for agent systems.... A few years ago I did a few speech about blockchain and smart contract, so I'll try to connect the dots exploring here an innovative approach combining blockchain technology, performance bonds, and zero-knowledge proofs to establish verifiable trust in AI agent systems - particularly in multi-agent workflows where ensuring accountability throughout the entire chain of delegation is paramount.\n\nFollow me: \ud83d\udc26 X | \ud83d\udcbc LinkedIn | \ud83d\udcec Substack | \ud83d\udcdd Medium (with voiceover)Follow me: \ud83d\udc26 X | \ud83d\udcbc LinkedIn | \ud83d\udcec Substack | \ud83d\udcdd Medium (with voiceover)... ## The Trust Problem with AI Agents\n\nWhen delegating tasks to AI agents, users face several trust challenges:\n\n\n\n**Performance Reliability**: Will the agent complete tasks according to specified standards?\n\n\n\n**Result Verification**: Can users verify the correctness of agent-produced outputs? \ud83d\udd0d **Security and Compliance**: Will agent operations adhere to regulatory and security requirements?\n\n\n\n**Delegation Accountability**: When multiple agents collaborate, who's ultimately responsible?\n\nTraditional approaches to these challenges rely primarily on centralized monitoring, reputation systems, or manual oversight - all of which suffer from scalability issues, single points of failure, or high operational costs.... This model mirrors traditional financial performance bonds but adapts them for the digital realm of AI services. By implementing these bonds on a blockchain, we gain several key advantages over traditional legal contracts:\n\n\n\n**Immutable Record**: The blockchain creates a permanent, tamper-proof record of all transactions and agreement terms \u2022 **Automated Execution**: The terms execute automatically when conditions are met without third-party intervention \u2022 **Transparent Verification**: All parties can independently verify the status and history of the bond... ### Key Benefits of Blockchain-Based Performance Bonds for AI Deployments\n\n**Aligned Incentives**: By risking tangible value (such as cryptocurrency), agent providers are motivated to deliver high-quality service **Automated Enforcement**: Smart contracts on the blockchain can evaluate performance against objective metrics **Regulatory Compliance**: Provides quantifiable assurance mechanisms for regulated industries **Reduced Dispute Costs**: Clear, machine-enforced criteria mitigate the need for legal interventions",
          "doi": null,
          "url": "https://artificialcode.substack.com/p/ensuring-trust-and-privacy-in-ai",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.4,
          "authority": 0.3,
          "final": 0.42,
          "evidence_snippet": "we focus on Domain-Specific Languages (DSLs), which LLMs often struggle to generate.",
          "why": "The paper discusses formal verification of code generated by AI, which relates to the claim about formal verifiability."
        }
      ],
      "status": "NEED_MANUAL",
      "notes": "No candidates met thresholds. Provide manual review."
    }
  ]
}