{
  "anchor_summary": {
    "topic": "Symbolic Governor in AI systems",
    "subareas": [
      "Formal verification",
      "Deterministic programming",
      "Trust in AI",
      "Agent-based systems"
    ],
    "key_terms": [
      "Symbolic Governor",
      "System 2",
      "root of trust",
      "deterministic code",
      "formal verification",
      "LLM"
    ],
    "likely_venues": [
      "AI conferences",
      "Systems journals",
      "Formal methods workshops"
    ],
    "exclusions": [
      "Non-deterministic systems",
      "Unverified AI models",
      "LLM-focused research"
    ]
  },
  "existing_citations_count": 0,
  "seed_expansion_used": false,
  "bib_path": "cases\\references.bib",
  "existing_entries_count": 11,
  "new_entries_added_count": 1,
  "new_bibkeys_added": [
    "Tam_Larrieux_2023"
  ],
  "warnings": [],
  "claims": [
    {
      "sid": "S0",
      "sentence": "The Symbolic Governor acts as the \"System 2\" component of the agent.",
      "rationale": "The term 'Symbolic Governor' and its role as 'System 2' need citation to support the claim.",
      "claim_type": "definition",
      "queries": [
        "Symbolic Governor in AI systems",
        "System 2 component in agent-based systems",
        "formal verification of deterministic programming with Symbolic Governor",
        "trust in AI through Symbolic Governor mechanisms",
        "root of trust in AI systems using Symbolic Governor"
      ],
      "selected": [
        {
          "paper_id": null,
          "title": "Regulating for trust: Can law establish trust in artificial intelligence?",
          "authors": [
            "Tam\u00f2\u2010Larrieux, Aurelia",
            "Guitton, Clement",
            "Mayer, Simon",
            "Lutz, Christoph"
          ],
          "year": 2023,
          "venue": null,
          "abstract": "actively pursuing initiatives\u2014as the US Executive Order on Safe, Secure, and Trustworthy AI, or the Bletchley Declaration on\nAI showcase\u2014based on the premise that the right regulatory strategy can shape trust in AI. To analyze the validity of this\npremise, we propose to consider the broader literature on trust in automation. On this basis, we constructed a framework to... regulations can modulate trust levels.1 She is not alone in doing so and many other EU documents share this\nrationale, implicitly or explicitly: For instance, in October 2021, the European Commission issued a call to adapt\nliability regulations to AI which stated that \u201c[t]he Commission\u2019s objective is to encourage the development and... minimizes distrust. We show that reducing every known complexity of an interaction is unrealistic, con-\ntradicting arguments that regulation can completely replace trust by eliminating uncertainty. Thus, the role of\nregulation becomes one of creating a framework that renders the uncertainty and vulnerability of interactions\nmanageable for society. Upon this basis, we provide a theoretical model for trust in Section 3, which captures... assumption. Instead, regulation can foster aspects that contribute to trust. Hill and O\u2019Hara (2006), for instance,\nargue that a (trusting) party has a maximum level of uncertainty and vulnerability that they are willing to accept.\nIf that threshold is crossed, the \u201cleap of faith\u201d (see Section 3) cannot occur. However, if the law can reduce uncer-... The literature review illustrates that regulation can reduce the uncertainty of interactions by setting external fac-\ntors to push the trusted agent to act according to the best interest of the trusting party (e.g., by enacting fiduciary\nduties or by punishing actions that harm a trusting party). These findings can be applied to the context of... AI. Primarily, and as discussed within the policymaking discourse (e.g., HLEG, 2019), the goal of policymakers is\nto create a framework of incentives that promote the development of trustworthy artificial agents, meaning agents\nwho are (extrinsically via regulation) motivated to uphold the trust placed in them (and act in the interest of the... artificial agent by reducing the uncertainty of the interaction to an acceptable degree. Especially within the\ncontext of human-machine interactions, optimizing the trust relationship is central, as both distrusting AI fully,\nand thereby underexploiting its potential, as well as overtrusting AI, leads to societally unwelcomed situations.",
          "doi": "10.1111/rego.12568",
          "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/rego.12568",
          "citation_count": null,
          "source": "perplexity",
          "seed_boost": 0.0,
          "relevance": 0.5,
          "support": 0.5,
          "authority": 0.2,
          "final": 0.45499999999999996,
          "evidence_snippet": "the goal of policymakers is to create a framework of incentives that promote the development of trustworthy artificial agents",
          "why": "The paper discusses the role of regulation in fostering trust in AI, which aligns with the concept of the Symbolic Governor as a component that manages trust and decision-making. However, it does not explicitly define the Symbolic Governor as 'System 2'."
        }
      ],
      "status": "NEED_MANUAL",
      "notes": "No candidates met thresholds. Provide manual review."
    },
    {
      "sid": "S1",
      "sentence": "It is the root of trust.",
      "rationale": "The phrase 'root of trust' is a specific term that requires citation to establish its definition and context.",
      "claim_type": "definition",
      "queries": [
        "Symbolic Governor in AI systems for formal verification",
        "Deterministic programming and root of trust in AI",
        "Trust in AI through Symbolic Governor mechanisms",
        "Agent-based systems with deterministic code and formal verification",
        "LLM integration with Symbolic Governor for trust in AI"
      ],
      "selected": [],
      "status": "NEED_MANUAL",
      "notes": "No reliable BibTeX (missing DOI)."
    },
    {
      "sid": "S2",
      "sentence": "Unlike the LLM, the Governor is implemented in deterministic code (e.",
      "rationale": "The statement makes a factual claim about the implementation of the Governor in deterministic code, which requires citation.",
      "claim_type": "method_description",
      "queries": [
        "Symbolic Governor in AI systems formal verification",
        "deterministic programming Symbolic Governor root of trust",
        "trust in AI systems Symbolic Governor deterministic code",
        "agent-based systems with Symbolic Governor formal methods",
        "LLM versus Symbolic Governor in AI trust"
      ],
      "selected": [],
      "status": "NEED_MANUAL",
      "notes": "No reliable BibTeX (missing DOI)."
    },
    {
      "sid": "S3",
      "sentence": "g., Python, Rust) and is formally verifiable.",
      "rationale": "The statement refers to formal verification, which is a specific area of research that typically requires citation to support claims about its applicability to programming languages.",
      "claim_type": "prior_work",
      "queries": [
        "Symbolic Governor in AI systems formal verification",
        "deterministic programming with Symbolic Governor",
        "trust in AI using root of trust and formal verification",
        "agent-based systems and Symbolic Governor",
        "LLM and deterministic code in AI systems"
      ],
      "selected": [],
      "status": "NEED_MANUAL",
      "notes": "No reliable BibTeX (missing DOI)."
    }
  ]
}